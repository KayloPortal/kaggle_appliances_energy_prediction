{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08564a27",
   "metadata": {},
   "source": [
    "## Experminet Notebook\n",
    "This notebook includes the process of training multiple models, monitoring performance, comparison and model selection over the same dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ceca9d",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0e1e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db010972",
   "metadata": {},
   "source": [
    "## Initiliazation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e2cd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffb65ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"./KAG_energydata_complete.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0742a86b",
   "metadata": {},
   "source": [
    "## Research Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f1a796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cyclic_encode(data, max_val):\n",
    "  return np.column_stack([\n",
    "        np.sin(2 * np.pi * data / max_val),\n",
    "        np.cos(2 * np.pi * data / max_val)\n",
    "    ])\n",
    "\n",
    "def ohe_encode(data):\n",
    "  encoder_data = OneHotEncoder(sparse_output=False)\n",
    "  return (encoder_data.fit_transform(data.reshape(-1, 1)), encoder_data)\n",
    "\n",
    "def binned_encode(data):\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9870756",
   "metadata": {},
   "source": [
    "A class to train models with different specifications in just one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c08ed69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelCreator:\n",
    "  def __init__(self, weekday_enc='ohe', hour_enc='ohe', reg_type='lasso', poly_deg=1):\n",
    "    self.params = {\n",
    "      'weekday_enc': weekday_enc,\n",
    "      'hour_enc': hour_enc,\n",
    "      'reg_type': reg_type,\n",
    "      'poly_deg': poly_deg\n",
    "    }\n",
    "    # self.model = None\n",
    "    # self.results = {}\n",
    "  def _get_preprocessor(self):\n",
    "    \"\"\"Private helper to build the encoding logic based on params.\"\"\"\n",
    "    # Logic to choose between One-Hot, Sin/Cos, or binned\n",
    "    # This is where your custom ColumnTransformer would live\n",
    "    pass\n",
    "\n",
    "  def _extract_weekday(date_string: str) -> int:\n",
    "    return datetime.strptime(date_string, \"%Y-%m-%d\").weekday()\n",
    "\n",
    "  def fit(self, X, y):\n",
    "    global dataframe\n",
    "    \"\"\"Constructs the pipeline and trains it.\"\"\"\n",
    "    # 1. Build Pipeline (Preprocessor -> Poly -> Scaler -> Regressor)\n",
    "    # 2. Store it in self.model\n",
    "    # 3. Use LassoCV or RidgeCV based on self.params['reg_type']\n",
    "    \n",
    "    # Extract date\n",
    "    date_column = dataframe.iloc[:,0].values\n",
    "    dataframe = dataframe.drop('date', axis=1)\n",
    "    \n",
    "    # Encoding\n",
    "    # --> Hours\n",
    "    v_slice_hours = np.vectorize(lambda x: x[11:13])\n",
    "    hours = v_slice_hours(date_column)\n",
    "    \n",
    "    if self.params['hour_enc'] == 'ohe':\n",
    "      hour_encoded, encoder_hour = ohe_encode(hours)\n",
    "      hour_column_names = encoder_hour.get_feature_names_out(['hour'])\n",
    "    \n",
    "    elif self.params['hour_enc'] == 'trig':\n",
    "      hour_encoded = cyclic_encode(hours, 24)\n",
    "      hour_column_names = np.array(['hour_sin', 'hour_cos'])\n",
    "    \n",
    "    elif self.params['hour_enc'] == 'binned':\n",
    "      pass\n",
    "    \n",
    "    else: raise Exception(\"this hour_enc is not supported or is not written correctly, please double check. supported hour_enc values: ohe, trig, binned\")\n",
    "    \n",
    "    hour_encoded_df = pd.DataFrame(hour_encoded, columns=hour_column_names)\n",
    "    dataframe = pd.concat([hour_encoded_df, dataframe], axis=1)\n",
    "    \n",
    "    # --> Weekdays\n",
    "    v_slice_date = np.vectorize(lambda x: x[0:10])\n",
    "    date_strings = v_slice_date(date_column)\n",
    "    v_extract_weekday = np.vectorize(self._extract_weekday)\n",
    "    weekdays = v_extract_weekday(date_strings)\n",
    "    \n",
    "    if self.params['hour_enc'] == 'ohe':\n",
    "      weekdays_encoded, encoder_weekdays = ohe_encode(weekdays)\n",
    "      weekdays_column_names = encoder_weekdays.get_feature_names_out(['weekday'])\n",
    "    \n",
    "    elif self.params['hour_enc'] == 'trig':\n",
    "      weekdays_encoded = cyclic_encode(weekdays, 7)\n",
    "      weekdays_column_names = np.array(['weekday_sin', 'weekday_cos'])\n",
    "    \n",
    "    elif self.params['hour_enc'] == 'binned':\n",
    "      pass\n",
    "    \n",
    "    week_encoded_df = pd.DataFrame(weekdays_encoded, columns=weekdays_column_names)\n",
    "    dataframe = pd.concat([week_encoded_df, dataframe], axis=1)\n",
    "    \n",
    "    # Polynomial Features\n",
    "    if self.params['poly_deg'] > 1:\n",
    "      pass\n",
    "    \n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    y_train = y_train.values.squeeze()\n",
    "    y_test = y_test.values.squeeze()\n",
    "    \n",
    "    self.X_test = X_test\n",
    "    self.y_test = y_test\n",
    "    self.X_train = X_train\n",
    "    self.y_train = y_train\n",
    "    \n",
    "    # PipeLine: Feature scaling & Training\n",
    "    \n",
    "    if self.params['reg_type'] == 'lasso':\n",
    "      self.pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('lasso', LassoCV(cv=5, random_state=42, tol=0.1, n_jobs=-1, max_iter=40000))\n",
    "      ])\n",
    "    \n",
    "    elif self.params['reg_type'] == 'ridge':\n",
    "      pass\n",
    "    \n",
    "    else: raise Exception(\"this reg_type is not supported or is not written correctly, please double check. supported reg_type values: lasso, ridge\")\n",
    "    \n",
    "    return self\n",
    "\n",
    "  def predict(self, X):\n",
    "    pass\n",
    "  \n",
    "  # def evaluate(self, X_test, y_test):\n",
    "    # \"\"\"Calculates metrics and stores them in self.results.\"\"\"\n",
    "    # y_pred = self.model.predict(X_test)\n",
    "    # self.results['rmse'] = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    # self.results['r2'] = r2_score(y_test, y_pred)\n",
    "    # return self.results"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
