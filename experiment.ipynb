{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08564a27",
   "metadata": {},
   "source": [
    "## Experminet Notebook\n",
    "This notebook includes the process of training multiple models, monitoring performance, comparison and model selection over the same dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ceca9d",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0e1e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db010972",
   "metadata": {},
   "source": [
    "## Initiliazation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3e2cd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV, LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cffb65ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Appliances</th>\n",
       "      <th>lights</th>\n",
       "      <th>T1</th>\n",
       "      <th>RH_1</th>\n",
       "      <th>T2</th>\n",
       "      <th>RH_2</th>\n",
       "      <th>T3</th>\n",
       "      <th>RH_3</th>\n",
       "      <th>T4</th>\n",
       "      <th>...</th>\n",
       "      <th>T9</th>\n",
       "      <th>RH_9</th>\n",
       "      <th>T_out</th>\n",
       "      <th>Press_mm_hg</th>\n",
       "      <th>RH_out</th>\n",
       "      <th>Windspeed</th>\n",
       "      <th>Visibility</th>\n",
       "      <th>Tdewpoint</th>\n",
       "      <th>rv1</th>\n",
       "      <th>rv2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-11 17:00:00</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>19.890000</td>\n",
       "      <td>47.596667</td>\n",
       "      <td>19.200000</td>\n",
       "      <td>44.790000</td>\n",
       "      <td>19.790000</td>\n",
       "      <td>44.730000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.033333</td>\n",
       "      <td>45.5300</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>733.5</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>13.275433</td>\n",
       "      <td>13.275433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-11 17:10:00</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>19.890000</td>\n",
       "      <td>46.693333</td>\n",
       "      <td>19.200000</td>\n",
       "      <td>44.722500</td>\n",
       "      <td>19.790000</td>\n",
       "      <td>44.790000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.066667</td>\n",
       "      <td>45.5600</td>\n",
       "      <td>6.483333</td>\n",
       "      <td>733.6</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>59.166667</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>18.606195</td>\n",
       "      <td>18.606195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-11 17:20:00</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>19.890000</td>\n",
       "      <td>46.300000</td>\n",
       "      <td>19.200000</td>\n",
       "      <td>44.626667</td>\n",
       "      <td>19.790000</td>\n",
       "      <td>44.933333</td>\n",
       "      <td>18.926667</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.5000</td>\n",
       "      <td>6.366667</td>\n",
       "      <td>733.7</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>55.333333</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>28.642668</td>\n",
       "      <td>28.642668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-11 17:30:00</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>19.890000</td>\n",
       "      <td>46.066667</td>\n",
       "      <td>19.200000</td>\n",
       "      <td>44.590000</td>\n",
       "      <td>19.790000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>18.890000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.4000</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>733.8</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>51.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>45.410389</td>\n",
       "      <td>45.410389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-11 17:40:00</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>19.890000</td>\n",
       "      <td>46.333333</td>\n",
       "      <td>19.200000</td>\n",
       "      <td>44.530000</td>\n",
       "      <td>19.790000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>18.890000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.4000</td>\n",
       "      <td>6.133333</td>\n",
       "      <td>733.9</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>47.666667</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>10.084097</td>\n",
       "      <td>10.084097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19730</th>\n",
       "      <td>2016-05-27 17:20:00</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>25.566667</td>\n",
       "      <td>46.560000</td>\n",
       "      <td>25.890000</td>\n",
       "      <td>42.025714</td>\n",
       "      <td>27.200000</td>\n",
       "      <td>41.163333</td>\n",
       "      <td>24.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>46.7900</td>\n",
       "      <td>22.733333</td>\n",
       "      <td>755.2</td>\n",
       "      <td>55.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>23.666667</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>43.096812</td>\n",
       "      <td>43.096812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19731</th>\n",
       "      <td>2016-05-27 17:30:00</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>46.500000</td>\n",
       "      <td>25.754000</td>\n",
       "      <td>42.080000</td>\n",
       "      <td>27.133333</td>\n",
       "      <td>41.223333</td>\n",
       "      <td>24.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>46.7900</td>\n",
       "      <td>22.600000</td>\n",
       "      <td>755.2</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>49.282940</td>\n",
       "      <td>49.282940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19732</th>\n",
       "      <td>2016-05-27 17:40:00</td>\n",
       "      <td>270</td>\n",
       "      <td>10</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>46.596667</td>\n",
       "      <td>25.628571</td>\n",
       "      <td>42.768571</td>\n",
       "      <td>27.050000</td>\n",
       "      <td>41.690000</td>\n",
       "      <td>24.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>46.7900</td>\n",
       "      <td>22.466667</td>\n",
       "      <td>755.2</td>\n",
       "      <td>56.333333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>25.333333</td>\n",
       "      <td>13.266667</td>\n",
       "      <td>29.199117</td>\n",
       "      <td>29.199117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19733</th>\n",
       "      <td>2016-05-27 17:50:00</td>\n",
       "      <td>420</td>\n",
       "      <td>10</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>46.990000</td>\n",
       "      <td>25.414000</td>\n",
       "      <td>43.036000</td>\n",
       "      <td>26.890000</td>\n",
       "      <td>41.290000</td>\n",
       "      <td>24.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>46.8175</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>755.2</td>\n",
       "      <td>56.666667</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>26.166667</td>\n",
       "      <td>13.233333</td>\n",
       "      <td>6.322784</td>\n",
       "      <td>6.322784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19734</th>\n",
       "      <td>2016-05-27 18:00:00</td>\n",
       "      <td>430</td>\n",
       "      <td>10</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>46.600000</td>\n",
       "      <td>25.264286</td>\n",
       "      <td>42.971429</td>\n",
       "      <td>26.823333</td>\n",
       "      <td>41.156667</td>\n",
       "      <td>24.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>46.8450</td>\n",
       "      <td>22.200000</td>\n",
       "      <td>755.2</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>13.200000</td>\n",
       "      <td>34.118851</td>\n",
       "      <td>34.118851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19735 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date  Appliances  lights         T1       RH_1  \\\n",
       "0      2016-01-11 17:00:00          60      30  19.890000  47.596667   \n",
       "1      2016-01-11 17:10:00          60      30  19.890000  46.693333   \n",
       "2      2016-01-11 17:20:00          50      30  19.890000  46.300000   \n",
       "3      2016-01-11 17:30:00          50      40  19.890000  46.066667   \n",
       "4      2016-01-11 17:40:00          60      40  19.890000  46.333333   \n",
       "...                    ...         ...     ...        ...        ...   \n",
       "19730  2016-05-27 17:20:00         100       0  25.566667  46.560000   \n",
       "19731  2016-05-27 17:30:00          90       0  25.500000  46.500000   \n",
       "19732  2016-05-27 17:40:00         270      10  25.500000  46.596667   \n",
       "19733  2016-05-27 17:50:00         420      10  25.500000  46.990000   \n",
       "19734  2016-05-27 18:00:00         430      10  25.500000  46.600000   \n",
       "\n",
       "              T2       RH_2         T3       RH_3         T4  ...         T9  \\\n",
       "0      19.200000  44.790000  19.790000  44.730000  19.000000  ...  17.033333   \n",
       "1      19.200000  44.722500  19.790000  44.790000  19.000000  ...  17.066667   \n",
       "2      19.200000  44.626667  19.790000  44.933333  18.926667  ...  17.000000   \n",
       "3      19.200000  44.590000  19.790000  45.000000  18.890000  ...  17.000000   \n",
       "4      19.200000  44.530000  19.790000  45.000000  18.890000  ...  17.000000   \n",
       "...          ...        ...        ...        ...        ...  ...        ...   \n",
       "19730  25.890000  42.025714  27.200000  41.163333  24.700000  ...  23.200000   \n",
       "19731  25.754000  42.080000  27.133333  41.223333  24.700000  ...  23.200000   \n",
       "19732  25.628571  42.768571  27.050000  41.690000  24.700000  ...  23.200000   \n",
       "19733  25.414000  43.036000  26.890000  41.290000  24.700000  ...  23.200000   \n",
       "19734  25.264286  42.971429  26.823333  41.156667  24.700000  ...  23.200000   \n",
       "\n",
       "          RH_9      T_out  Press_mm_hg     RH_out  Windspeed  Visibility  \\\n",
       "0      45.5300   6.600000        733.5  92.000000   7.000000   63.000000   \n",
       "1      45.5600   6.483333        733.6  92.000000   6.666667   59.166667   \n",
       "2      45.5000   6.366667        733.7  92.000000   6.333333   55.333333   \n",
       "3      45.4000   6.250000        733.8  92.000000   6.000000   51.500000   \n",
       "4      45.4000   6.133333        733.9  92.000000   5.666667   47.666667   \n",
       "...        ...        ...          ...        ...        ...         ...   \n",
       "19730  46.7900  22.733333        755.2  55.666667   3.333333   23.666667   \n",
       "19731  46.7900  22.600000        755.2  56.000000   3.500000   24.500000   \n",
       "19732  46.7900  22.466667        755.2  56.333333   3.666667   25.333333   \n",
       "19733  46.8175  22.333333        755.2  56.666667   3.833333   26.166667   \n",
       "19734  46.8450  22.200000        755.2  57.000000   4.000000   27.000000   \n",
       "\n",
       "       Tdewpoint        rv1        rv2  \n",
       "0       5.300000  13.275433  13.275433  \n",
       "1       5.200000  18.606195  18.606195  \n",
       "2       5.100000  28.642668  28.642668  \n",
       "3       5.000000  45.410389  45.410389  \n",
       "4       4.900000  10.084097  10.084097  \n",
       "...          ...        ...        ...  \n",
       "19730  13.333333  43.096812  43.096812  \n",
       "19731  13.300000  49.282940  49.282940  \n",
       "19732  13.266667  29.199117  29.199117  \n",
       "19733  13.233333   6.322784   6.322784  \n",
       "19734  13.200000  34.118851  34.118851  \n",
       "\n",
       "[19735 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv(\"./KAG_energydata_complete.csv\")\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0742a86b",
   "metadata": {},
   "source": [
    "## Research Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9870756",
   "metadata": {},
   "source": [
    "A class to train models with different specifications in just one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c08ed69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelCreator:\n",
    "  def __init__(self, weekday_enc='ohe', hour_enc='ohe', reg_type='lasso', poly_deg=1, random_state=None, trainer=None, split_rate=0.2):\n",
    "    self.params = {\n",
    "      'weekday_enc': weekday_enc,\n",
    "      'hour_enc': hour_enc,\n",
    "      'reg_type': reg_type,\n",
    "      'poly_deg': poly_deg,\n",
    "      'random_state': random_state,\n",
    "      'trainer': trainer,\n",
    "      'split_rate': split_rate\n",
    "    }\n",
    "    # self.model = None\n",
    "    # self.results = {}\n",
    "    self.encoders = {\n",
    "      'hour': None,\n",
    "      'weekday': None\n",
    "    }\n",
    "    self.ohe_counts = None\n",
    "    self.poly = None\n",
    "    \n",
    "  def __cyclic_encode(self, data, max_val):\n",
    "    return np.column_stack([\n",
    "        np.sin(2 * np.pi * data / max_val),\n",
    "        np.cos(2 * np.pi * data / max_val)\n",
    "    ])\n",
    "\n",
    "  def __ohe_encode(self, data, key):\n",
    "    if self.encoders[key] == None:\n",
    "      encoder_data = OneHotEncoder(sparse_output=False)\n",
    "      self.encoders[key] = encoder_data\n",
    "      encoder_data.fit(data.reshape(-1, 1))\n",
    "      # return (encoder_data.fit_transform(data.reshape(-1, 1)), encoder_data)\n",
    "    return (self.encoders[key].transform(data.reshape(-1, 1)), self.encoders[key])\n",
    "      \n",
    "\n",
    "  def __binned_encode(self, data):\n",
    "    pass\n",
    "    \n",
    "  def _process_dataframe(self, df):\n",
    "    # --- Handle The Dataframe ---\n",
    "    dataframe = df.copy()\n",
    "    date_column = pd.to_datetime(dataframe['date'])\n",
    "    hours = date_column.dt.hour.values # extracts hour column as [0, 0, ..., 2, 2, ...]\n",
    "    weekdays = date_column.dt.weekday.values # extracting weekdays like [0, 0, ..., 1, 1, ...]\n",
    "    dataframe = dataframe.drop('date', axis=1)\n",
    "    \n",
    "    # --- Handle Hour Encoding ---\n",
    "    if self.params['hour_enc'] == 'ohe':\n",
    "      hour_encoded, encoder_hour = self.__ohe_encode(hours, 'hour')\n",
    "      hour_column_names = encoder_hour.get_feature_names_out(['hour'])\n",
    "      self.encoder_hour = encoder_hour\n",
    "    elif self.params['hour_enc'] == 'trig':\n",
    "      hour_encoded = self.__cyclic_encode(hours, 24)\n",
    "      hour_column_names = np.array(['hour_sin', 'hour_cos'])\n",
    "    elif self.params['hour_enc'] == 'binned':\n",
    "      pass\n",
    "    else: raise Exception(\"this hour_enc is not supported or is not written correctly, please double check. supported hour_enc values: ohe, trig, binned\")\n",
    "    # put the hour-of-day into dataframe\n",
    "    hour_encoded_df = pd.DataFrame(hour_encoded, columns=hour_column_names)\n",
    "    dataframe = pd.concat([hour_encoded_df, dataframe], axis=1)\n",
    "    \n",
    "    # --- Handle Weekday Encoding ---   \n",
    "    if self.params['weekday_enc'] == 'ohe':\n",
    "      weekdays_encoded, encoder_weekdays = self.__ohe_encode(weekdays, 'weekday')\n",
    "      weekdays_column_names = encoder_weekdays.get_feature_names_out(['weekday'])\n",
    "    elif self.params['weekday_enc'] == 'trig':\n",
    "      weekdays_encoded = self.__cyclic_encode(weekdays, 7)\n",
    "      weekdays_column_names = np.array(['weekday_sin', 'weekday_cos'])\n",
    "    elif self.params['weekday_enc'] == 'binned':\n",
    "      pass\n",
    "    # Putting weekday columns into dataframe\n",
    "    week_encoded_df = pd.DataFrame(weekdays_encoded, columns=weekdays_column_names)\n",
    "    dataframe = pd.concat([week_encoded_df, dataframe], axis=1)\n",
    "    \n",
    "    # --- Handle Polynomial Features ---\n",
    "    if 'Appliances' in df:\n",
    "      X = dataframe.drop('Appliances', axis=1)\n",
    "      y = dataframe[['Appliances']]\n",
    "    else:\n",
    "      X = dataframe\n",
    "      y = None\n",
    "    \n",
    "    if self.params['poly_deg'] > 1:\n",
    "      if self.poly == None:\n",
    "        poly = PolynomialFeatures(degree=self.params['poly_deg'], include_bias=False)\n",
    "        X = poly.fit_transform(X)\n",
    "        self.poly = poly\n",
    "      else:\n",
    "        poly = self.poly\n",
    "        X = poly.transform(X)\n",
    "      # Filtering out bad ohe combinations\n",
    "      if self.ohe_counts == None:\n",
    "        ohe_counts = []\n",
    "        if self.params['weekday_enc'] == 'ohe':\n",
    "          if self.params['hour_enc'] == 'ohe':\n",
    "            ohe_counts = [(0, 7), (7, 7 + 24)]\n",
    "          elif self.params['hour_enc'] == 'binned':\n",
    "            pass\n",
    "          elif self.params['hour_enc'] == 'trig':\n",
    "            ohe_counts = [(0, 7)]\n",
    "        if self.params['weekday_enc'] == 'trig':\n",
    "          if self.params['hour_enc'] == 'ohe':\n",
    "            ohe_counts = [(2, 2 + 24)]\n",
    "          elif self.params['hour_enc'] == 'binned':\n",
    "            pass\n",
    "        if self.params['weekday_enc'] == 'binned':\n",
    "          if self.params['hour_enc'] == 'ohe':\n",
    "            pass\n",
    "          elif self.params['hour_enc'] == 'binned':\n",
    "            pass\n",
    "          elif self.params['hour_enc'] == 'trig':\n",
    "            pass\n",
    "        self.ohe_counts = ohe_counts\n",
    "        self.valid = []\n",
    "        if len(ohe_counts) > 0:\n",
    "          feature_powers = self.poly.powers_\n",
    "          for i in range(len(feature_powers)):\n",
    "            # if (feature_powers[i, ohe_counts[0][0]:ohe_counts[0][1]].sum() <= 1\n",
    "            #     and feature_powers[i, ohe_counts[1][0]:ohe_counts[1][1]].sum() <= 1): self.valid.append(i)\n",
    "            isValid = True\n",
    "            for item in ohe_counts:\n",
    "              if feature_powers[i, item[0]:item[1]].sum() > 1: isValid = False\n",
    "            if isValid: self.valid.append(i)\n",
    "      \n",
    "      if len(self.ohe_counts) > 0:\n",
    "        X = X[:, self.valid]\n",
    "    return (X, y)      \n",
    "\n",
    "  # def _extract_weekday(self, date_string: str) -> int:\n",
    "  #   return datetime.strptime(date_string, \"%Y-%m-%d\").weekday()\n",
    "\n",
    "  def fit(self, df):\n",
    "    \"\"\"Constructs the pipeline and trains it.\"\"\"\n",
    "    \n",
    "    X, y = self._process_dataframe(df)\n",
    "\n",
    "    # --- Split ---\n",
    "    if self.params['split_rate'] == 0: \n",
    "      # This means we don't want to split our data, we want the model to be trained on the whole dataframe.\n",
    "      # ATTENTION: You're allowed to use self.evaluate only when you've set the split_rate a positive number.\n",
    "      X_train = X\n",
    "      y_train = y\n",
    "    else:\n",
    "      # This means we want a test subset to be extracted from our dataframe\n",
    "      X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=self.params['split_rate'], random_state=self.params['random_state'])\n",
    "      y_test = y_test.values.squeeze()\n",
    "      self.X_test = X_test\n",
    "      self.y_test = y_test\n",
    "    y_train = y_train.values.squeeze()\n",
    "    self.X_train = X_train\n",
    "    self.y_train = y_train\n",
    "    \n",
    "    # --- PipeLine: Feature scaling & Training ---\n",
    "    if self.params['reg_type'] == 'lasso':\n",
    "      if self.params['trainer'] == None:\n",
    "        self.params['trainer'] = LassoCV(cv=5, random_state=self.params['random_state'], n_jobs=-1, max_iter=10000)\n",
    "      self.pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('lasso', self.params['trainer'])\n",
    "      ])\n",
    "    elif self.params['reg_type'] == 'ridge':\n",
    "      if self.params['trainer'] == None:\n",
    "        self.params['trainer'] = RidgeCV()\n",
    "      self.pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('ridge', self.params['trainer'])        \n",
    "      ])\n",
    "    elif self.params['reg_type'] == 'regressor':\n",
    "      if self.params['trainer'] == None:\n",
    "        self.params['trainer'] = LinearRegression()\n",
    "      self.pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', self.params['trainer'])        \n",
    "      ])\n",
    "    else: raise Exception(\"this reg_type is not supported or is not written correctly, please double check. supported reg_type values: lasso, ridge, regressor\")\n",
    "  \n",
    "    self.pipeline.fit(X_train, y_train)\n",
    "\n",
    "    return self\n",
    "\n",
    "  def predict(self, df, return_labels=False):\n",
    "    \"\"\"Gets raw dataframe and outputs model's predictions. Dataframe's structure should be exactly like the original dataframe, with the exception that including Appliance column is optional\"\"\"\n",
    "    X, y = self._process_dataframe(df)\n",
    "    y_pred = self.pipeline.predict(X)\n",
    "    if return_labels: return (y_pred, y)\n",
    "    return y_pred\n",
    "    \n",
    "  \n",
    "  # def evaluate(self, X_test, y_test):\n",
    "    # \"\"\"Calculates metrics and stores them in self.results.\"\"\"\n",
    "    # y_pred = self.model.predict(X_test)\n",
    "    # self.results['rmse'] = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    # self.results['r2'] = r2_score(y_test, y_pred)\n",
    "    # return self.results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5da804",
   "metadata": {},
   "source": [
    "## Training Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd942c9",
   "metadata": {},
   "source": [
    "### How to Use The Engine: Training a Basic Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3c20887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear_model = ModelCreator(hour_enc='ohe', weekday_enc='ohe', poly_deg=1, reg_type='regressor', random_state=42\n",
    "#                             , trainer=LinearRegression(random_state_24)) # Declare specifications\n",
    "# linear_model.fit(dataframe) # Train the model\n",
    "# y_pred = linear_model.pipeline.predict(linear_model.X_test) # Raise answers\n",
    "# RMSE = np.sqrt(mean_squared_error(linear_model.y_test, y_pred)) # calculate error\n",
    "# RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b84ea95",
   "metadata": {},
   "source": [
    "### Choosing The Proper Encoding For Linear(degree=1) Models\n",
    "\n",
    "Four models were trained differing only in encoding methods. As expected, the model with one-hot encoding for both variables wins in generalization(due to ratios being closer to one), it also has the highest ability of explaining the variance of the data(Highest $R^2$) along with lowest average prediction inaccuracy(lowest RMSE on both train and test). However, it's obvious that all these models are underfitting and giving us garbage results, we can see that by comaring MAE(represents average distance between the model's predicted value and actual value) **MAE=50.88(Wh)** to average(mean) energy consumption in our data **mean=97.69(Wh)**. It's clear that the model is so innaccurate in guessing our target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294e1391",
   "metadata": {},
   "source": [
    "| Deg | Hour | Week | Reg | Train R² | Test R² | Train RMSE | Test RMSE | Ratio (Test/Train RMSE) | Test MAE |\n",
    "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| 1 | ohe | ohe | lasso | 0.235 | 0.232 | 90.19 | 87.68 | 0.972 | 50.88 |\n",
    "| 1 | ohe | trig | lasso | 0.232 | 0.228 | 90.37 | 87.92 | 0.973 | 50.85 |\n",
    "| 1 | trig | ohe | lasso | 0.203 | 0.205 | 92.08 | 89.19 | 0.969 | 51.68 |\n",
    "| 1 | trig | trig | lasso | 0.200 | 0.201 | 92.26 | 89.40 | 0.969 | 51.62 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b20586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Deg | Hour | Week | Reg | Train R² | Test R² | Train RMSE | Test RMSE | Ratio (Test/Train RMSE) | Test MAE |\n",
      "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
      "| 1 | ohe | ohe | lasso | 0.235 | 0.232 | 90.19 | 87.68 | 0.972 | 50.88 |\n",
      "| 1 | ohe | trig | lasso | 0.232 | 0.228 | 90.37 | 87.92 | 0.973 | 50.85 |\n",
      "| 1 | trig | ohe | lasso | 0.203 | 0.205 | 92.08 | 89.19 | 0.969 | 51.68 |\n",
      "| 1 | trig | trig | lasso | 0.200 | 0.201 | 92.26 | 89.40 | 0.969 | 51.62 |\n"
     ]
    }
   ],
   "source": [
    "# Define your experimental grid\n",
    "experiments = [\n",
    "    {'poly_deg': 1, 'hour_enc': 'ohe', 'weekday_enc': 'ohe', 'reg_type': 'lasso', 'trainer': LassoCV(cv=5, random_state=24, n_jobs=-1, max_iter=10000)},\n",
    "    {'poly_deg': 1, 'hour_enc': 'ohe', 'weekday_enc': 'trig', 'reg_type': 'lasso', 'trainer': LassoCV(cv=5, random_state=24, n_jobs=-1, max_iter=10000)},\n",
    "    {'poly_deg': 1, 'hour_enc': 'trig', 'weekday_enc': 'ohe', 'reg_type': 'lasso', 'trainer': LassoCV(cv=5, random_state=24, n_jobs=-1, max_iter=10000)},\n",
    "    {'poly_deg': 1, 'hour_enc': 'trig', 'weekday_enc': 'trig', 'reg_type': 'lasso', 'trainer': LassoCV(cv=5, random_state=24, n_jobs=-1, max_iter=10000)},\n",
    "]\n",
    "\n",
    "print(\"| Deg | Hour | Week | Reg | Train R² | Test R² | Train RMSE | Test RMSE | Ratio (Test/Train RMSE) | Test MAE |\")\n",
    "print(\"|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\")\n",
    "\n",
    "for params in experiments:\n",
    "    # 1. Initialize and Fit\n",
    "    model = ModelCreator(**params, random_state=42)\n",
    "    model.fit(dataframe) # Assuming your raw data is in 'dataframe'\n",
    "    \n",
    "    # 2. Get Metrics\n",
    "    # (Using the evaluate method logic we discussed)\n",
    "    y_train_pred = model.pipeline.predict(model.X_train)\n",
    "    y_test_pred = model.pipeline.predict(model.X_test)\n",
    "    \n",
    "    tr_r2 = r2_score(model.y_train, y_train_pred)\n",
    "    ts_r2 = r2_score(model.y_test, y_test_pred)\n",
    "    tr_rmse = np.sqrt(mean_squared_error(model.y_train, y_train_pred))\n",
    "    ts_rmse = np.sqrt(mean_squared_error(model.y_test, y_test_pred))\n",
    "    \n",
    "    mae = mean_absolute_error(model.y_test, y_test_pred)\n",
    "    \n",
    "    rmse_ratio = ts_rmse / tr_rmse\n",
    "    \n",
    "    # 3. Print Markdown Row\n",
    "    print(f\"| {params['poly_deg']} | {params['hour_enc']} | {params['weekday_enc']} | {params['reg_type']} | \"\n",
    "          f\"{tr_r2:.3f} | {ts_r2:.3f} | {tr_rmse:.2f} | {ts_rmse:.2f} | {rmse_ratio:.3f} | {mae:.2f} |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0114a380",
   "metadata": {},
   "source": [
    "### Choosing The Proper Regularization Type For Linear(degree=1) Models\n",
    "We concluded from the previous cell that OHE encoding is the best for our linear models, three models with different regularization methods were tested and they all gave the same results. The reason to this is obvious, we talked earlier briefly in the ReadMe that $\\lambda$ tries to move the model in bias-variance tradeoff towards the sweetspot. Our linear model is underfitting, it has high bias and low variance, therefore the model tries to increase the model's variance to move it towards the sweetspot by decreasing $\\lambda$, but it reaches the model's boundries, meaning $\\lambda$ gets near zero and tries it best to increase the variance, but the model has reached its limits and it can't go further(can't have more variance). Hence, all models, regardless of their regularization method, reach the same spot.\n",
    "\n",
    "In another words, even when $\\lambda = 0$(normal regression without regularization) the model is underfitting, meaning it has high bias and what it needs is more variance, and any $\\lambda > 0$ provides less variance, hence, the model tries to push $\\lambda$ towards zero, pushing all regulrazied regressions towards becoming a normal regression without regularization, therefore all four models end up being the same(not excatly the same, but almost identical).\n",
    "\n",
    "Considering the observations above, we conclude that when our model is underfitting, there's nothing regularization L1 or L2 can do, but to give us the same model we had. Utilizing regularization methods like L1 and L2 when the model is underfitting doesn't provide any value.\n",
    "\n",
    "Regularization is meant to reduce model's complexity to decrease variance, using it when the model is too simple and needs more variance doesn't help, therefore, the best linear model with degree one is a regular linear regression model with one-hot encoded weekdays and hours but without regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277dd7c9",
   "metadata": {},
   "source": [
    "| Deg | Hour | Week | Reg | Train R² | Test R² | Train RMSE | Test RMSE | Ratio (Test/Train RMSE) | Best $\\lambda$ | CrossVal |\n",
    "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| 1 | ohe | ohe | lasso | 0.235 | 0.232 | 90.19 | 87.68 | 0.972 | 0.0197 | 5 Folds |\n",
    "| 1 | ohe | ohe | ridge | 0.235 | 0.232 | 90.19 | 87.68 | 0.972 | 11.4976 | LOOCV |\n",
    "| 1 | ohe | ohe | ridge | 0.235 | 0.232 | 90.19 | 87.68 | 0.972 | 11.4976 | 5 Folds |\n",
    "| 1 | ohe | ohe | regressor | 0.235 | 0.232 | 90.19 | 87.69 | 0.972 | - | - |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3a6236",
   "metadata": {},
   "source": [
    "But you might ask, if L1 and L2 try to push the $\\lambda$ to zero for this model, why does this happens for lasso($\\lambda = 0.0197$) but not for ridge($\\lambda = 11.4976$)? Even when we try to train a ridge model with alphas=[0.0197, 11.4976], we expect the model to pick the less lambda based on the logic we provided above to increase the model's variance, but it picks 11.4976(check the code below to see), does this mean our logic is wrong? Well, not percisely.\n",
    "\n",
    "While it seems that ridge is working against this logic, this is not actually true. I trained two ridge models, one with $\\lambda = 0.0197$ and another with $\\lambda = 11.4976$, and look these wonderful table, they both raised the same results! This means both $\\lambda$ values give our model almost the same variance, they both create the same model. But why?\n",
    "\n",
    "The reason comes from how Ridge treats our data. Lasso is much more aggressive in penalizing variance comparing to Ridge, hence it's much more sensitive to changing the value of $\\lambda$. As shown in the table below, the same change for $\\lambda$ effects Lasso regression remarkably while Ridge regression stays almost the same.\n",
    "\n",
    "But if ridge regression with $\\lambda = 0.0197$ and $\\lambda = 11.4976$ are almost identical, why doesn't the model choose the lower lambda? that lower lambda might have the same performance but just be a little bit better, but this amount is so small the model can't see it properly.\n",
    "\n",
    "Our data is noisy, and K-Fold cross validation isn't perfect. Lasso with $\\lambda = 0.0197$ might be $0.00001$ better in performance, but the noise and very little uncontrolable bias that can happen in K-Fold CV, can hide this fact, making the model think $\\lambda = 11.4976$ is an option that's a little bit better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a31476",
   "metadata": {},
   "source": [
    "| Deg | Hour | Week | Reg | Train R² | Test R² | Train RMSE | Test RMSE | Ratio (Test/Train RMSE) | Fixed $\\lambda$ | CrossVal |\n",
    "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| 1 | ohe | ohe | ridge | 0.235 | 0.232 | 90.19 | 87.69 | 0.972 | 0.0197 | 5 Folds |\n",
    "| 1 | ohe | ohe | ridge | 0.235 | 0.232 | 90.19 | 87.68 | 0.972 | 11.4976 | 5 Folds |\n",
    "| 1 | ohe | ohe | lasso | 0.235 | 0.232 | 90.19 | 87.68 | 0.972 | 0.0197 | 5 Folds |\n",
    "| 1 | ohe | ohe | lasso | 0.056 | 0.060 | 100.22 | 97.01 | 0.968 | 11.4976 | 5 Folds |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c2eeba",
   "metadata": {},
   "source": [
    "Here's a visual summary:\n",
    "\n",
    "<img src=\"./visuals/diagram-bias-variance-tradeoff.png\" alt=\"bias variance tradeoff explained with diagram\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74ec3d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Deg | Hour | Week | Reg | Train R² | Test R² | Train RMSE | Test RMSE | Ratio (Test/Train RMSE) | Best $\\lambda$ |\n",
      "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
      "| 1 | ohe | ohe | lasso | 0.235 | 0.232 | 90.19 | 87.68 | 0.972 | 0.0197 |\n",
      "| 1 | ohe | ohe | ridge | 0.235 | 0.232 | 90.19 | 87.68 | 0.972 | 11.4976 |\n",
      "| 1 | ohe | ohe | ridge | 0.235 | 0.232 | 90.19 | 87.68 | 0.972 | 11.4976 |\n",
      "| 1 | ohe | ohe | regressor | 0.235 | 0.232 | 90.19 | 87.69 | 0.972 | -1.0000 |\n",
      "| 1 | ohe | ohe | ridge | 0.235 | 0.232 | 90.19 | 87.68 | 0.972 | 11.4976 |\n",
      "| 1 | ohe | ohe | ridge | 0.235 | 0.232 | 90.19 | 87.69 | 0.972 | 0.0197 |\n",
      "| 1 | ohe | ohe | ridge | 0.235 | 0.232 | 90.19 | 87.68 | 0.972 | 11.4976 |\n",
      "| 1 | ohe | ohe | lasso | 0.235 | 0.232 | 90.19 | 87.68 | 0.972 | 0.0197 |\n",
      "| 1 | ohe | ohe | lasso | 0.056 | 0.060 | 100.22 | 97.01 | 0.968 | 11.4976 |\n"
     ]
    }
   ],
   "source": [
    "# Define your experimental grid\n",
    "alphas = np.logspace(-3, 3, 100)\n",
    "experiments = [\n",
    "    {'poly_deg': 1, 'hour_enc': 'ohe', 'weekday_enc': 'ohe', 'reg_type': 'lasso', 'trainer': LassoCV(cv=5, random_state=24, n_jobs=-1, max_iter=10000)},\n",
    "    {'poly_deg': 1, 'hour_enc': 'ohe', 'weekday_enc': 'ohe', 'reg_type': 'ridge', 'trainer': RidgeCV(cv=None, alphas=alphas)},\n",
    "    {'poly_deg': 1, 'hour_enc': 'ohe', 'weekday_enc': 'ohe', 'reg_type': 'ridge', 'trainer': RidgeCV(cv=5, alphas=alphas)},\n",
    "    {'poly_deg': 1, 'hour_enc': 'ohe', 'weekday_enc': 'ohe', 'reg_type': 'regressor', 'trainer': LinearRegression()},\n",
    "    {'poly_deg': 1, 'hour_enc': 'ohe', 'weekday_enc': 'ohe', 'reg_type': 'ridge', 'trainer': RidgeCV(cv=5, alphas=[0.0197, 11.4976])},\n",
    "    {'poly_deg': 1, 'hour_enc': 'ohe', 'weekday_enc': 'ohe', 'reg_type': 'ridge', 'trainer': RidgeCV(cv=5, alphas=[0.0197])},\n",
    "    {'poly_deg': 1, 'hour_enc': 'ohe', 'weekday_enc': 'ohe', 'reg_type': 'ridge', 'trainer': RidgeCV(cv=5, alphas=[11.4976])},\n",
    "    {'poly_deg': 1, 'hour_enc': 'ohe', 'weekday_enc': 'ohe', 'reg_type': 'lasso', 'trainer': LassoCV(cv=5, alphas=[0.0197], random_state=24, n_jobs=-1, max_iter=10000)},\n",
    "    {'poly_deg': 1, 'hour_enc': 'ohe', 'weekday_enc': 'ohe', 'reg_type': 'lasso', 'trainer': LassoCV(cv=5, alphas=[11.4976], random_state=24, n_jobs=-1, max_iter=10000)},\n",
    "]\n",
    "\n",
    "print(\"| Deg | Hour | Week | Reg | Train R² | Test R² | Train RMSE | Test RMSE | Ratio (Test/Train RMSE) | Best $\\\\lambda$ |\")\n",
    "print(\"|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\")\n",
    "\n",
    "for params in experiments:\n",
    "    # 1. Initialize and Fit\n",
    "    model = ModelCreator(**params, random_state=42)\n",
    "    model.fit(dataframe) # Assuming your raw data is in 'dataframe'\n",
    "    \n",
    "    # 2. Get Metrics\n",
    "    # (Using the evaluate method logic we discussed)\n",
    "    y_train_pred = model.pipeline.predict(model.X_train)\n",
    "    y_test_pred = model.pipeline.predict(model.X_test)\n",
    "    \n",
    "    tr_r2 = r2_score(model.y_train, y_train_pred)\n",
    "    ts_r2 = r2_score(model.y_test, y_test_pred)\n",
    "    tr_rmse = np.sqrt(mean_squared_error(model.y_train, y_train_pred))\n",
    "    ts_rmse = np.sqrt(mean_squared_error(model.y_test, y_test_pred))\n",
    "    \n",
    "    rmse_ratio = ts_rmse / tr_rmse\n",
    "    \n",
    "    try:\n",
    "        alpha = model.pipeline.named_steps[params['reg_type']].alpha_\n",
    "    except AttributeError: alpha = -1\n",
    "    \n",
    "    # 3. Print Markdown Row\n",
    "    print(f\"| {params['poly_deg']} | {params['hour_enc']} | {params['weekday_enc']} | {params['reg_type']} | \"\n",
    "          f\"{tr_r2:.3f} | {ts_r2:.3f} | {tr_rmse:.2f} | {ts_rmse:.2f} | {rmse_ratio:.3f} | {alpha:.4f} |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d58425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your experimental grid\n",
    "experiments = [\n",
    "    {'poly_deg': 1, 'hour_enc': 'ohe', 'weekday_enc': 'ohe', 'reg_type': 'lasso', 'trainer': LassoCV(cv=5, random_state=24, n_jobs=-1, max_iter=10000)},\n",
    "    {'poly_deg': 2, 'hour_enc': 'ohe', 'weekday_enc': 'ohe', 'reg_type': 'lasso', 'trainer': LassoCV(cv=5, random_state=24, n_jobs=-1, max_iter=10000)},\n",
    "    {'poly_deg': 2, 'hour_enc': 'ohe', 'weekday_enc': 'ohe', 'reg_type': 'lasso', 'trainer': RidgeCV(cv=5)},\n",
    "]\n",
    "\n",
    "print(\"| Deg | Hour | Week | Reg | Train R² | Test R² | Train RMSE | Test RMSE | Ratio (Test/Train RMSE) |\")\n",
    "print(\"|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\")\n",
    "\n",
    "for params in experiments:\n",
    "    # 1. Initialize and Fit\n",
    "    model = ModelCreator(**params, random_state=42)\n",
    "    model.fit(dataframe) # Assuming your raw data is in 'dataframe'\n",
    "    \n",
    "    # 2. Get Metrics\n",
    "    # (Using the evaluate method logic we discussed)\n",
    "    y_train_pred = model.pipeline.predict(model.X_train)\n",
    "    y_test_pred = model.pipeline.predict(model.X_test)\n",
    "    \n",
    "    tr_r2 = r2_score(model.y_train, y_train_pred)\n",
    "    ts_r2 = r2_score(model.y_test, y_test_pred)\n",
    "    tr_rmse = np.sqrt(mean_squared_error(model.y_train, y_train_pred))\n",
    "    ts_rmse = np.sqrt(mean_squared_error(model.y_test, y_test_pred))\n",
    "    \n",
    "    rmse_ratio = ts_rmse / tr_rmse\n",
    "    \n",
    "    # 3. Print Markdown Row\n",
    "    print(f\"| {params['poly_deg']} | {params['hour_enc']} | {params['weekday_enc']} | {params['reg_type']} | \"\n",
    "          f\"{tr_r2:.3f} | {ts_r2:.3f} | {tr_rmse:.2f} | {ts_rmse:.2f} | {rmse_ratio:.3f} |\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
